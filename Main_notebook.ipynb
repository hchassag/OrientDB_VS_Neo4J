{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>OrientDB VS Neo4J : la guerre des graphes</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Auteurs : Chassagnon - Fischer - Sow </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/n6KNXdq/pilotes-img.jpg\" width=\"1100\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline\n",
    "####  Introduction\n",
    "#### 1. OrientDB une base de donnée multimodèle <br>\n",
    "  > ##### a. Présentation de la base de donnée \n",
    "  > ##### b. Installation et premiers pas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Comparaison avec Neo4J\n",
    "  > ##### a. Notre approche (présenter le dataset ici)\n",
    "  > ##### b. Création des bases de données\n",
    "  > ##### c. Requêtes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Conclusion sur la comparaison et Limites de notre approche <br>\n",
    "####  Conclusion générale "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\"> Le big data, cette technologie révolutionnaire qui va changer nos vies. C'est en ces termes qu'est présenté ce concept né fin des années 90 aux États-unis. Ce terme est en effet maintenant devenu un \"buzz word\" utilisé à tout va dans les sphères médiatiques et dans le marketing pour attirer l'attention ou susciter l'engouement autour de technologies qui dans la majorité des cas ne sont pas totalement maîtrisées. Cependant, derrière ce terme se cache des solutions certes innovantes mais qui dépassent la simple traduction littérale de \"grosses masses de données\" qu'on lui attribue. Elle n'est en réalité pas seulement liée au volume de données mais aussi et surtout à la variété de celles-ci (leur hétérogénéité), la vélocité à laquelle elle nous parviennent, leur valeur et véracité. On parle des cinq V du big data. \n",
    "L'écosystème du big data a notamment fait sa révolution grâce à l'évolution des architectures informatiques et à la création de la technique de MapReduce par google (dans le framework Hadoop). Mais aussi au changement de paradigme que représente le passage des bases de données relationnées utilisant le language SQL (Structured query Language) aux systèmes NoSQL (Not Only SQL). Malgré la domination du SQL qui reste le type de base de donnée prépondérant, nous assistons à l'émergence du NoSQL propulsé notamment par la dynamique de nouvelles start-up qui sont souvent rachetés par les géants \"traditionnels\" du big data que sont Oracle, IBM, Google. \n",
    "Parmi ces technologies NoSQL, nous distinguons notamment les bases de données de type graphes qui stockent la donnée sous forme de graphes en liant des neouds (Nodes - Vertex) grâce à des relations (Links - Edges). Elle sont très utilisées par les géants du net comme Facebook ou Twitter pour représenter les relations qui existent entre les utilisateurs. \n",
    "Dans cet exposé, nous allons présenter un système de gestion de base de données (SGBD) de type graphe OrientDB en le comparant notamment à un SGBD orienté graphe concurrant Neo4J. Nous utiliserons leurs \"drivers\" python que sont respectivement pyrorient and py2neo. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. **OrientDB une base de donnée multimodèle**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Présentation de la base de donnée "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OrientDB a vu le jour en 2010 grâce à Luca Garulli. OrientDB a très vite revendiqué le titre de premier SGBD multimodèle marquant, selon son créateur, la nouvelle révolution du NoSQL. Multimodèle ici se référe au fait que OrientDB a été réfléchie pour pouvoir notamment gérer à la fois des données de type graphes, documents et clés-valeurs. Ce qui marque une certaine révolution. \n",
    "Sa particularité est qu'elle inclue une couche du language SQL. Cependant, au lieu de parcourir les relations (edges) grâce à des jointures (une des plus importante feature du SQL), des liens (Links) sont utilisés. Il s'agit de liaisons directes par enregistrement d’un pointeur vers l’objet. Ce qui la différencie des SGBD relationnels. Cela conduit à une récupération rapide de données reliées par rapport aux jointures dans un Système de Gestion de Base de Données (SGBD) qui pour nous est un hybride Relationnel-Graphe. Nous évoquerons dans la suite de l'exposé cette dernière comme une SGBD-G. \n",
    "De tous les types de stockage de données évoqués ci-dessus, le type graphe utilisé aussi par Neo4J est décrit dans la littérature comme le plus structurant en NoSQL (VERGNES, 2015). L'essence même de la donnée est ici conservée. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/Fx7Bdfg/graph-eg.png\" width=\"800\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Figure 1 : Exemple de SGBD orienté graphe </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les SGBD graphes ont comme évoqué une gestion des données basée sur des nœuds (les individus divers), possédant un certain nombre de propriétés (informations), reliés entre eux par des arêtes (edges). Les graphes peuvent gérer des modèles très connectés avec une grande quantité de données en gardant leur structure au niveau du réseau ainsi formé. Elles utilisent les propriétées de la théorie des graphes.\n",
    "Écrite en Java, OrientDB s’appuie sur une communauté open source pour se développer, dirigée par OrientDB LTD qui est une filiale de SAP. Cette dernière l'a acquise après le rachat de CallidusCloud en 2018. La stratégie de SAP concernant OrientDB a été claire dès le rachat. La structure resterait assez indépendante, l'équipe maintenue et le développement open source. Ainsi, vous pouvez contribuer facilement à OrientDB et dialoguer avec l'équipe [ici](https://github.com/orientechnologies/orientdb).\n",
    "Elle possède toutes les fonctions natives d’un graph data base avec la flexibilité et la rapidité d’un document store (OrientDB).\n",
    "Plusieurs versions d’OrientDB existent, une version entreprise et une autre communautaire. Nous traiterons ici seulement de cette dernière, gratuite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Installation et premiers pas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous détaillerons dans cette partie l'installation et la mise en place de la base de donnée. Nous utiliserons de la documentation issues principalement de notre expérience personnelle avec OrientDB, ainsi que le [MOOC de Udemy sur OrientDB](https://www.udemy.com/join/login-popup/?next=/course/orientdb-getting-started/learn/lecture/1726168#overview) et le [site officiel d’OrientDB](www.orientdb.org). Toutes ces étapes ne concernent que la version gratuite (appelée Community Edition) disponible sous licence Apache2 (utilisation et distribution à des fins personnels, académiques et commerciales sans restriction). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prérequis : OrientDB nécessite de posséder les systèmes d'exploitation qui peuvent implémenter une machine virtuelle Java : \n",
    "- Microsoft Windows 95/NT et versions postérieures, \n",
    "- Mac OS X, \n",
    "- Linux,\n",
    "- Solaris...<br>\n",
    "\n",
    "Mais aussi d'avoir une version de Java ultérieure à 1.7. Lors de notre première prise en main, nous avons constaté que même certaines versions ultérieures avaient du mal à être supportées par OrientDB. Nous conseillons si vous rencontrez des problèmes d'execution du fichier orientDB de désinstaller complétement Java et de réinstaller l'ensemble du JDK 8.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’installation est très simple et comporte 3 étapes principales : \n",
    "Téléchargement // Décompression - Unzip // Lancement\n",
    " \n",
    "-          Télécharger et installer Java :  https://www.java.com/fr/ (version offline) s’il n’est pas déjà présent sur la machine\n",
    "-          Télécharger OrientDB selon le système d’exploitation : https://www.orientdb.org/download\n",
    "-          Décompresser/unzip le dossier, renommer le dossier de version en orientdb\n",
    "\n",
    "Pour obtenir le JDK 8 vous pouvez directement consulter le [site d'Oracle](https://www.oracle.com/fr/java/technologies/javase/javase-jdk8-downloads.html). Aussi, si vous désirez installer le Code source, vous pouvez le faire [ici](https://orientdb.com/docs/2.2.x/Tutorial-Installation.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir téléchargé sur votre ordinateur OrientDB et bien vérifié avoir la version de Java, vous pourrez suivre les instructions suivantes pour finaliser votre installation. \n",
    "### <center><font color='red'>Mac OS X </font> - <font color='orange'>Windows</font> - <font color='red'>Linux </font> </center> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Ouvrir l’invite de commande :<br>\n",
    " > <font color='orange'>Démarrer et rechercher l’invite de commande </font> <br>\n",
    " > <font color='red'>Clic droit sur le fichier server.sh du dossier orientdb et l’ouvrir avec Terminal </font> \n",
    " \n",
    "-  Changer le répertoire de travail au sous dossier bin du dossier orientdb. <br>\n",
    "Pour le dossier sur le bureau : <br>\n",
    " > <font color='orange'>C:\\Users\\Axel>cd Desktop\\orientdb\\bin </font> <br>\n",
    " > <font color='red'> MacBook-Pro-de-Ibrahima:bin ibrahimasow$  ~/Desktop/orientdb/bin</font> \n",
    " \n",
    "- Lancer le serveur OrientDB : <br>\n",
    " > <font color='orange'> C:\\Users\\Axel\\Desktop\\orientdb\\bin>server.bat </font> <br>\n",
    " > <font color='red'> MacBook-Pro-de-Ibrahima:bin ibrahimasow$ ./server.sh </font> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/0Jr0GjF/orient-terminal.png\" width=\"1100\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Figure 2 : Lancement du server OrientDB à partir du terminal </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lancer le serveur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si besoin, autorisez l’accès aux réseaux à Java. Lorsque cela est demandé saisissez votre mot de passe pour autoriser l'installation de la base de donnéee. <br>\n",
    "Pour lancer le serveur OrientDB, il vous faut :\n",
    "   - lancer le fichier ./server.sh depuis votre invite de commande (terminal sur mac ou linux)\n",
    "   - sur votre navigateur ouvrir votre localhost sur le 2480. Vous pouvez faire cela à l'adresse suivante : http://localhost:2480/studio/index.html#/ <br>\n",
    "   \n",
    "<u>**Remarque**</u> : Notez que OrientDB Studio (le desktop de la base de donnée) se trouve au niveau du port 2480. Nous verrons plus tard que pour se connecter avec le driver Python il faudra utiliser le port 2424. \n",
    "Vous tomberez sur la page d'accueil de votre base de donnée. Vous êtes prêt, à vous maintenant de changer le monde avec de magnifiques graphes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/5KQ2nsn/lp-orientdb.png\" width=\"1100\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Figure 3 : Vue de la page de connexion du serveur local d'OrientDB Desktop </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pourrez vérifier à l'aide de requête simple si tout est OK en accédant à la base de donnée créée par défaut (demodb). Vous pourrez par exemple requêter toute la table Profiles grâce à la commande suivante: **SELECT * FROM Profiles**.\n",
    "Notez que 3 utilisateurs (admin, reader et writer) sont créés par défaut par OrientDB à chaque création de base de donnée. Veuillez de plus à garder précieusement votre code de connexion, il est unique pour l'ensemble de les bases de données que vous administrerez. En cas d'oublie, il vous faudra suivre une procédure assez fastidieuse qui implique d'altérer les fichiers configurations (nous vous conseillons de ne pas tenter ces opérations qui peuvent aboutir à une défection de certaines fonctions importantes).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utiliser un driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OrientDB a comme évoqué été pensée et construire avec du Java pur, elle utilise SQL comme language de requête ce qui en fait un outil assez apprécié dans la communauté est qu'elle a dès ses débuts permis le développement de \"drivers\" (des programmes informatiques qui implémentent un protocole pour se connecter à une base de donnée). Ainsi, plusieurs développeurs extérieurs au projet ont programmés des interfaces de connection avec les langagues les plus populaires. On retrouve un driver Java (le plus actif et maintenu) mais aussi et surtout un driver Python appelé [Pyorient](https://github.com/mogui/pyorient). \n",
    "Pyorient s'installe facilement avec l'outil de gestion de packages de python pip. Il est nécessaire d'avoir une version de Python ultérieure à la 2.7 (la plupart des ordinateurs étant déjà équipé de Python 2.7. Nous vous conseillons cependant d'utiliser Python 3 (>=3.7 étant l'idéal) pour pouvoir profiter pleinement des possibilités de ce driver. \n",
    "- Installation de Pyorient : sur votre invite de commande (terminal) : <font color='blue'> **pip install pyorient** </font> <br>\n",
    "- pour importer pyorient dans votre IDE :  <font color='blue'> **import pyorient**</font> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. **Comparaison avec Neo4J**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center> @versions : Python : 3.7  //  Pyorient = 1.5.5  // Py2neo = 2020.0.0  //   OrientDB = 3.1.4 //   Neo4J : 4.1.1 // Sous Mac Catalina et Windows 7</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Disclaimer : Notre travail porte sur les versions citées ci-dessus, nos conclusions peuvent donc différer de celles d'autres travaux.</center> \n",
    "> #### a. Notre approche\n",
    " > #### - Stratégie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de présenter au mieux OrientDB et de le comparer à Neo4J, nous avons choisi de le faire sur une stratégie comparative bien définie. Nous avons effet, choisi de travailler à deux sur cette partie. Un de nous a travaillé uniquement avec OrientDB/pyOrient et un autre uniquement avec Neo4J/py2neo. Le but étant de partir d'un même jeu de donnée (celui des Championnats du monde de Formule 1 de 1950 à 2020), construire pour chacun la base de donnéee de son côté avec PyOrient pour l'un et Py2neo pour l'autre. Ensuite, les mêmes requêtes sont faites pour chacune des bases de donnéee. Enfin, chacun partage son expérience à l'autre et essaie de comprendre en quoi la technologie qu'il a utilisé est meilleure ou moins performant par rapport à l'autre. \n",
    "Nous avons de plus décidé d'un nombre de critères bien défini qui nous semble pertinent pour une bonne utilisation d'une base de donnée orientée graphe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > #### - Jeu de données "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données, disponible sur [kaggle](https://www.kaggle.com/rohanrao/formula-1-world-championship-1950-2020), regroupe l'ensemble des informations relatives au déroulé et aux résultats des Grands Prix de Formule 1 depuis 1950. On y retrouve des informations sur les écuries (constructors), les épreuves de qualification (qualifying), les pilotes (drivers), les courses (races), les temps (laps stops)… Dans un soucis de cohérence avec les questions qui nous intéressent et d'adaptation de ce jeu de données aux capacités de nos ordinateurs, nous avons choisi de ne travailler que sur les tables suivantes : Constructors - Drivers - Races - Circuits - Results. Ces tables sont à elles seules suffisantes pour prendre en main OrientDB et Neo4J et réaliser au mieux la comparaison. Aussi, parce qu'il s'agit de données assez importantes, toutes ces tables sont reliées entre elles par des clés étrangers très pertinent dans les bases de données relationnelles. Nous allons voir qu'elles servent aussi énormément en NoSQL. La figure 4 présente contenu de chaque table. Aussi, dans un souci de simplification et de focalisation sur l'essentiel, nous n'allons extraire de chaque table que des variables qui nous semblent pertinentes e.g : Pour Drivers code et dob (date-of-birth) ne seront pas utilisées pour construire nos bases de données. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/1rBZfXz/dtst.png\" width=\"1100\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Figure 4 : Overview de notre jeu de donnée </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### b. Création des bases de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie, nous détaillons la création de notre base de donnée. Pour chacune des deux technologies le même cheminement est suivi à savoir la création des noeuds (Nodes, Vertex) et celle des relations (Edges). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   > ## Sur OrientDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous procédons d'abord à l'importation de l'ensemble des librairies nécessaires. Le driver Pyorient se décline dans sa forme usuelle pour dialoguer avec le serveur Orientdb en tant que client. Il existe aussi un module PyOrient OGM pour \"Object-Graph Mapper for PyOrient\" qui offre une interface de haut niveau (par rapport au dialogue avec la machine) pour les bases de données de type Graphe. Nous n'utiliserons ici que le module Pyorient. Nous importons de même les packages qui nous permettrons de mener à bien nos process de \"data wrangling\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyorient \n",
    "from pyorient.ogm import *\n",
    "from csv import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time as tm\n",
    "import seaborn as sns\n",
    "import psutil "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur Pyorient avec de dialoguer avec le serveur il est nécessaire de créer un client (une sorte de session). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pyorient.OrientDB(\"localhost\", 2424)\n",
    "sessionToken = client.get_session_token()\n",
    "client.set_session_token(True)\n",
    "session_id = client.connect(\"root\", \"merlin\") # root correspond ici à notre id admin et merlin le mot de passe pour accéder au serveur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de ce client nous créer notre base de données Formula1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.db_create(\n",
    " # \"Formula1\",\n",
    "  # pyorient.DB_TYPE_GRAPH,\n",
    "   # pyorient.STORAGE_TYPE_PLOCAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.db_open(\"Formula1\", \"root\", \"merlin\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyorient offre plusieurs commandes très simples et intuitives pour vérifier sa connexion, avoir quelques infos auprès du serveur. vous pouvez les retrouver [ici](https://orientdb.com/docs/2.2.x/PyOrient-Client.html). Nous affichons ci-dessous la liste des bases de données disponibles côté serveur ainsi que la taille de celle que  nous venons d'ouvrir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblist = client.db_list()\n",
    "dblist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.db_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous procédons ci-dessous à la création des noeuds de notre de données. Dans le vocabulaire d'OrientDB un noeud correspond à un VERTEX. Mathématiquement cela est très logique vu que cela correspond à un sommet en géométrie. Python étant un language orienté objet, nous utiliserons dans la partie ci-dessous plusieurs attributs et méthodes. Cette caractéristique de python fait qu'il est très adapté à une base de donnée orienté graphe. En effet, ici aussi on parle de classes et d'objets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création des noeuds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > ####  Données écuries :  Constructors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = tm.time()\n",
    "path_to_data = \"/Users/ibrahimasow/Desktop/formula_1/\"\n",
    "file= open(path_to_data+'constructors.csv','r')\n",
    "constructors = pd.read_csv(file)\n",
    "constructors = constructors.rename(columns={\"name\": \"cons_name\", \"nationality\": \"cons_nationality\"})\n",
    "constructors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constructorId = constructors['constructorId'].to_list()\n",
    "constructorRef = constructors['constructorRef'].to_list()\n",
    "cons_name = constructors['cons_name'].to_list()\n",
    "cons_nationality = constructors['cons_nationality'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode command() permet d'écrire et d'éxécuter des requêtes qui sont comme il est possible de le constater ci-dessous du SQL. Une alternative à command est query : \n",
    "    client.query(\"CREATE Class Constructors EXTENDS V\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.command(\"CREATE Class Constructors EXTENDS V\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons constaté avec l'utilisation de Pyorient que le client avait tendance à se déconnecter du serveur en perdant ainsi son token (traduction littérale : jeton; comme une clef donnant l'autorisation à notre client de se connecter). Nous avons donc décidé avant chaque grosse requête de set (mettre) notre token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set_session_token(True); # ; pour ne pas voir l'output dans notre notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons aussi constaté que pour certaines requêtes le temps de dialogue minimal (de 30s) instauré par les développeurs du package ne suffisait pas. Nous avons donc décider d'outre-passer cette limite temporelle en la fixant à 150s. Si vous utilisez ce feature évitez par contre de mettre un temps beaucoup trop long; cela risquerait de vous envoyer dans des infinite loops (des itérations à l'infini de votre programmation et un crash de votre ordinateur)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "socks = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "socks.settimeout(150.0) # set timeout is the attr of socks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'envoyer notre neoud au serveur nous avons choisi d'utiliser l'une des fonctionalités les plus intéressantes d'OrientDB que repréesente le Batch. Le Batch en informatique est une technique qui permet une automatisation d'une suite de commandes exécutées en série sur un ordinateur sans qu'il soit nécessaire qu'un opérateur intervienne pour réaliser cette opération ([JDN, 2020](https://www.journaldunet.fr/web-tech/dictionnaire-du-webmastering/1203563-batch-definition-traduction/#:~:text=Le%20terme%20batch%20d%C3%A9signe%20en,expression%20%22traitement%20par%20lots%22.)). Les process Batch permettent ainsi en Big data d'optimiser la performance lorsque des tâches répétitives comme présentées ci-dessous sont à réaliser. Dans notre, plus commandes SQL ne différant que d'un caractère (les Id) est à réaliser. Nous initialisons donc notre commande batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Batch Commands Array\n",
    "batch_cmds = ['begin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous réalisons les itérations nécessaires et affectons les commandes SQL unitaires à la liste précédemment initialisée.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b in zip(range(len(cons_name)), constructorId):\n",
    "    command = (\"CREATE VERTEX Constructors \"\n",
    "               \"SET constructorId = '%s', constructorRef = '%s', cons_name ='%s', cons_nationality ='%s'\"\n",
    "          % (b,\n",
    "             constructorRef[a],\n",
    "             cons_name[a],\n",
    "             cons_nationality[a]\n",
    "            ))\n",
    "    batch_cmds.append(command)\n",
    "# Add Batch Commit\n",
    "batch_cmds.append('commit retry 100;')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous séparons chaque commande unitaire par un ; (séparateur de commande usuel en SQL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join with Semicolons\n",
    "cmd = ';'.join(batch_cmds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et exécutons la commande Batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Commands\n",
    "results = client.batch(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sans ce procédé, la tâche que nous venons d'éxécuter n'aurait pas pu se faire (crash répétitifs de notre connexion client-serveur) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous répétons cette technique pour chacune des autres jeu de données à notre disposition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Données circuit :  Circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file= open(path_to_data+'circuits.csv','r')\n",
    "circuits = pd.read_csv(file)\n",
    "circuits = circuits.rename(columns={\"name\": \"circuits_name\"})\n",
    "circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuitId = circuits['circuitId'].to_list()\n",
    "circuits_name = circuits['circuits_name'].to_list()\n",
    "location = circuits['location'].to_list()\n",
    "country = circuits['country'].to_list()\n",
    "lat = circuits['lat'].to_list()\n",
    "lng = circuits['lng'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set_session_token(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.command(\"CREATE Class Circuits EXTENDS V\")\n",
    "# Initialize Batch Commands Array\n",
    "batch_cmds = ['begin']\n",
    "for a, b in zip(range(len(circuitId)), circuitId):\n",
    "    command = (\"CREATE VERTEX Circuits \"\n",
    "               \"SET circuitId = '%s',name ='%s', location ='%s', country='%s', lat='%s', lng='%s'\"\n",
    "          % (b,\n",
    "             circuits_name[a],\n",
    "             location[a],\n",
    "             country[a],\n",
    "             lat[a],\n",
    "             lng[a]\n",
    "            ))\n",
    "    batch_cmds.append(command)\n",
    "    # Add Batch Commit\n",
    "batch_cmds.append('commit retry 100;')\n",
    "# Join with Semicolons\n",
    "cmd = ';'.join(batch_cmds)\n",
    "# Execute Commands\n",
    "results = client.batch(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Données courses :  Races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file= open(path_to_data+'races.csv','r')\n",
    "races = pd.read_csv(file)\n",
    "races = races.rename(columns={\"name\": \"races_name\"})\n",
    "races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raceId = races['raceId'].to_list()\n",
    "year = races['year'].to_list()\n",
    "round = races['round'].to_list()\n",
    "circuitId = races['circuitId'].to_list()\n",
    "races_name = races['races_name'].to_list()\n",
    "date = races['date'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set_session_token(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.command(\"CREATE Class Races EXTENDS V\")\n",
    "# Initialize Batch Commands Array\n",
    "batch_cmds = ['begin']\n",
    "for a, b, c, d, e in zip(range(len(raceId)), raceId, year, round, circuitId):\n",
    "    command = (\"CREATE VERTEX Races \"\n",
    "               \"SET raceId = '%s', year = '%s', round ='%s', circuitId ='%s', races_name='%s', date='%s'\"\n",
    "          % (b, c, d, e,\n",
    "             races_name[a],\n",
    "             date[a]\n",
    "            ))\n",
    "    batch_cmds.append(command)\n",
    "# Add Batch Commit\n",
    "batch_cmds.append('commit retry 100;')\n",
    "# Join with Semicolons\n",
    "cmd = ';'.join(batch_cmds)\n",
    "# Execute Commands\n",
    "results = client.batch(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Données pilotes : Drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file= open(path_to_data+'drivers.csv','r')\n",
    "drivers = pd.read_csv(file)\n",
    "drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers['surname'] = drivers['surname'].str.replace(\"d'Orey\",'dOrey')\n",
    "drivers['surname'] = drivers['surname'].str.replace(\"d'Ambrosio\",'dAmbrosio')\n",
    "drivers['surname'] = drivers['surname'].str.replace(\"O'Connor\",'OConnor')\n",
    "drivers['surname'] = drivers['surname'].str.replace(\"O'Brien\",'OBrien')\n",
    "\n",
    "drivers = drivers.replace(to_replace =r\"\\N\", \n",
    "                 value =\"NA\") \n",
    "driverId = drivers['driverId'].to_list()\n",
    "driverRef = drivers['driverRef'].to_list()\n",
    "number = drivers['number'].to_list()\n",
    "code = drivers['code'].to_list()\n",
    "forename = drivers['forename'].to_list()\n",
    "surname = drivers['surname'].to_list()\n",
    "nationality = drivers['nationality'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.command(\"CREATE Class Drivers EXTENDS V\")\n",
    "# Initialize Batch Commands Array\n",
    "batch_cmds = ['begin']\n",
    "for a, b in zip(range(len(driverId)), driverId):\n",
    "    command = (\"CREATE VERTEX Drivers \"\n",
    "               \"SET driverId = '%s', driverRef = '%s', forename ='%s', surname= '%s', nationality= '%s'\"\n",
    "          % (b,\n",
    "             driverRef[a],\n",
    "             forename[a],\n",
    "             surname[a],\n",
    "             nationality[a]\n",
    "            ))\n",
    "    batch_cmds.append(command)\n",
    "# Add Batch Commit\n",
    "batch_cmds.append('commit retry 100;')\n",
    "# Join with Semicolons\n",
    "cmd = ';'.join(batch_cmds)\n",
    "# Execute Commands\n",
    "results = client.batch(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Données résultats : Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file= open(path_to_data+'results.csv','r')\n",
    "results = pd.read_csv(file)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.replace(to_replace =r\"\\N\", \n",
    "                 value =\"NA\") \n",
    "\n",
    "resultId = results['resultId'].to_list()\n",
    "raceId = results['raceId'].to_list()\n",
    "driverId = results['driverId'].to_list()\n",
    "constructorId = results['constructorId'].to_list()\n",
    "grid = results['grid'].to_list()\n",
    "position = results['position'].to_list()\n",
    "positionOrder = results['positionOrder'].to_list()\n",
    "points = results['points'].to_list()\n",
    "laps = results['laps'].to_list()\n",
    "time = results['time'].to_list()\n",
    "rank = results['rank'].to_list()\n",
    "statusId = results['statusId'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.command(\"CREATE Class Results EXTENDS V\")\n",
    "batch_cmds = ['begin']\n",
    "for a, b, c,d, e, f,g,h,i, in zip(resultId, raceId, driverId, constructorId, position, positionOrder, points, rank, statusId):\n",
    "    command = (\"CREATE VERTEX Results \"\n",
    "               \"SET resultId = '%s', raceId = '%s', driverId ='%s', constructorId ='%s',position= '%s', positionOrder='%s', points= '%s',rank='%s' , statusId= '%s'\"\n",
    "          % (a,b,c,d,e,f,g,h,i\n",
    "            ))\n",
    "    batch_cmds.append(command)\n",
    "    \n",
    "batch_cmds.append('commit retry 100;')\n",
    "# Join with Semicolons\n",
    "cmd = ';'.join(batch_cmds)\n",
    "# Execute Commands\n",
    "results = client.batch(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir créée nos noeuds, il est maintenant temps de les relier les uns aux autres grâce à des relations. Pour ce jeu de données nous avons réfléchi aux relations les plus pertinentes possibles et avons défini les suivantes : \n",
    "-  Races <font color='red'>**took_place_on** </font> Circuits : Relation course s'est passé dans circuit\n",
    "-  Results <font color='red'>**results_of**</font> Races : Relation résultat de la course\n",
    "-  Driver result on Race; <font color='red'>**d_results**</font> : Relation résultat du pilote \n",
    "-  Constructor result on Race; <font color='red'>**c_results**</font> : Relation résultat de l'écurie \n",
    "-  Pilote <font color='red'>**participated_to**</font> Race : Relation pilote a participité à la course "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La création de relations entre noeuds dans orientdb n'est cependant à notre avis pas très intuitif. En effet, comme évoqué dans la présentation du SGBD bien qu'OrientDB accepte ,le SQL comme language de requête, elle ne permet pas de faire des jointures de tables (ce qui est très utilise lorsque le dataset est constitué de plusieurs tables liées les unes aux autres par des clés étrangers). A la place, des \"LINKS\" sont proposés (ce serait selon l'équipe de développement plus en phase avec l'esprit NoSQL). \n",
    "Afin de créer ces liens entre tables (noeuds) nous avons donc opté pour une stratégie assez peu orthodoxe mais très logique au vu de notre dataset. Nous avons en effet le caractère central de la table Results (où on retrouve tous les clés étrangers) et avons bouclé sur l'ensemble de ces données afin de crééer nos relations. \n",
    "Nous avons de plus dans un soucis d'optimisation utilisé la méthode Batch avec le même principe évoqué précédemment. \n",
    "La création de ces fameuses \"edges\" nécessite en SQL de créer des liens du type : <font color='orange'> ..FROM Vertex X To Vertex Y... </font> <br>\n",
    "Dans les chunks ci-dessous vous trouverez les codes correspondants à la création de relations entres nodes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Relation course s'est passé dans circuit : Races took_place_on Circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.command(\"CREATE Class took_place_on EXTENDS E\") # Course s'est passé au Circuit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Batch Commands Array\n",
    "batch_cmds = ['begin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in zip(races[\"raceId\"], races[\"circuitId\"]):\n",
    "    command = (\"CREATE EDGE took_place_on FROM (SELECT * FROM Races WHERE raceId = %s) TO \" \n",
    "          \"(SELECT * FROM Circuits WHERE circuitId = %s)\"\n",
    "    %(i,\n",
    "      j\n",
    "    ))\n",
    "    batch_cmds.append(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Batch Commit\n",
    "batch_cmds.append('commit retry 100;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join with Semicolons\n",
    "cmd = ';'.join(batch_cmds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Commands\n",
    "results = client.batch(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Relation result de la course : Results results_of Races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.command(\"CREATE Class results_of EXTENDS E\") # Driver/Constructeur result for a Course\n",
    "# Initialize Batch Commands Array\n",
    "batch_cmds = ['begin']\n",
    "for i, j in zip(results[\"resultId\"], results[\"raceId\"]):\n",
    "    command = (\"CREATE EDGE results_of FROM (SELECT * FROM Results WHERE resultId = %s) TO \" \n",
    "          \"(SELECT * FROM Races WHERE raceId = %s)\"\n",
    "    %(i,\n",
    "      j\n",
    "    ))\n",
    "    batch_cmds.append(command)\n",
    "    # Add Batch Commit\n",
    "batch_cmds.append('commit retry 100;')\n",
    "# Join with Semicolons\n",
    "cmd = ';'.join(batch_cmds)\n",
    "# Execute Commands\n",
    "results = client.batch(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Relation résultat du pilote : Driver result on Race; d_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.command(\"CREATE Class d_results EXTENDS E\") # Driver result for a Race\n",
    "batch_cmds = ['begin']\n",
    "for i, j in zip(results[\"driverId\"], results[\"resultId\"]):\n",
    "    command = (\"CREATE EDGE d_results FROM (SELECT * FROM Drivers WHERE driverId = %s) TO \" \n",
    "          \"(SELECT * FROM Results WHERE resultId = %s)\"\n",
    "    %(i,\n",
    "      j\n",
    "    ))\n",
    "    batch_cmds.append(command)\n",
    "# Add Batch Commit\n",
    "batch_cmds.append('commit retry 100;')\n",
    "# Join with Semicolons\n",
    "cmd = ';'.join(batch_cmds)\n",
    "# Execute Commands\n",
    "results = client.batch(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Relation résultat de l'écurie : Constructor result on Race; c_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.command(\"CREATE Class c_results EXTENDS E\") # Constructeur result for a Race\n",
    "batch_cmds = ['begin']\n",
    "for i, j in zip(results[\"constructorId\"], results[\"resultId\"]):\n",
    "    command = (\"CREATE EDGE c_results FROM (SELECT * FROM Constructors WHERE constructorId = %s) TO \" \n",
    "          \"(SELECT * FROM Results WHERE resultId = %s)\"\n",
    "    %(i,\n",
    "      j\n",
    "    ))\n",
    "    batch_cmds.append(command)\n",
    "# Add Batch Commit\n",
    "batch_cmds.append('commit retry 100;')\n",
    "# Join with Semicolons\n",
    "cmd = ';'.join(batch_cmds)\n",
    "# Execute Commands\n",
    "results = client.batch(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Relation pilote a participité à la course : Pilote participated to Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.command(\"CREATE Class participated_to EXTENDS E\") # Driver/Constructeur a participé à Course\n",
    "batch_cmds = ['begin']\n",
    "for i, j in zip(results[\"driverId\"], results[\"raceId\"]):\n",
    "    command = (\"CREATE EDGE participated_to FROM (SELECT * FROM Drivers WHERE driverId = %s) TO \" \n",
    "          \"(SELECT * FROM Races WHERE raceId = %s)\"\n",
    "    %(i,\n",
    "      j\n",
    "    ))\n",
    "    batch_cmds.append(command)\n",
    "# Add Batch Commit\n",
    "batch_cmds.append('commit retry 100;')\n",
    "# Join with Semicolons\n",
    "cmd = ';'.join(batch_cmds)\n",
    "# Execute Commands\n",
    "results = client.batch(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print(\"La création de la base de donnée avec pyOrient a nécessité\" + \" \" + str(round(end - start, 2)) + \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orientdb propose une alternative pour créer une base de donnée. Il est effet possible d'utiliser la méthode ETL. Le principe est créer sa base de base à partir d'un fichier JSON en trois étapes : Extract - Transform - Load. Dans la première étape, le jeu de donnée est extraite à partir de sa source, dans la deuxième les données sont transformées afin de correspondre à nos attentes. Il est ainsi possible dans cette de crééer des noeuds et de relations. La dernière étape permet de charger les données dans la base de donnée cible. Cette méthode est extrêmement intéressante lorsque l'on travaille avec un volume de données important. Nous avons essayé cette alternative proposéee par Orientdb et avons constaté une prise en main assez rapide dès lors qu'on a compris le principe général de l'ETL. Cette méthode comparéee à l'envoie de données à partir de Python est beaucoup plus rapide et adapté au Big Data. Ceci même comparé aux commandes Batch que nous avons réalisé ci-dessus. <br>\n",
    "Pour faire de l'ETL avec Orientdb il est nécessaire de disposer d'un éditeur de texte adapté (nous recommandons Sublime Text ou Visual Studio Code). Vous trouverez le principe de l'ETL avec Orientdb dans la documentation du SGBD [ici](https://orientdb.com/docs/2.2.x/ETL-Introduction.html) et un exemple détaillant bien chaque étape [ici](https://orientdb.com/docs/2.2.x/Import-the-Database-of-Beers.html). La figure 5 montre les commandes JSON que nous avons utilisé pour l'ETL des données sur les courses (Races). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/hXvbDcw/races-etl.png\" width=\"1100\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Figure 5 : ETL sur données des pilotes  </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous calculons ici le coût en termes de mémoire de cette étape de création de la base de donnée sous OrientDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_use_orient = psutil.virtual_memory()[2] # percent – the percentage usage that is calculated as (total – available) / total * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   > ## Sur Neo4J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie, la phase de création de la base de donnée est aussi réalisée aeveec Neo4J. Pour cela, nous utilisons le Driver py2neo qui contrairement à pyorient posséde des modules Graph, Node et Relationship qui sont d'une très grande aide pour définir sans effort supplémentaire les noeuds et relations entre eux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph, Node, Relationship\n",
    "from  py2neo.ogm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour commencer, il est nécessaire dans Neo4j de lancer une nouvelle base de donnée (selon nos recherches py2neo ne permettant pas de créer directement une base de donnée).  Le code Python ne fera que injecter des données et des relations créées dans une base Neo4j. \n",
    "Nous avons donc en amont :\n",
    "-  Ouvrir Neo4j et créer une nouvel base locale intitulée \"Formula_1\"\n",
    "-  avec mot de passe : Neo4j\n",
    "-  La demarrer \n",
    "-  et l'ouvrir <br>\n",
    "\n",
    "Pour se cconnecter à la base de donnée, il faut se connecter au port 7687 du serveur localhost. Notez qu'il faut dans certains cas préciser littéralement l'adresse localhost (bolt://127.0.0.1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_db = Graph(\"bolt://127.0.0.1:7687\", auth=(\"neo4j\", \"merlin\")) # Nous nous connectons avec commme admin id : neo4j et comme mot de passe : merlin (oui oui lui même !)\n",
    "# graph_db.run(\"MATCH (n) DETACH DELETE n\") Cette commande nettoie la base de donnée de tout ce qu'elle contient. ELle permet de s'assurer qu'on parte d'une base de donnée vide. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme avec pyorient, nous allons dans un premier temps nous construirons les noeuds à partir de nos documents csv. Pour ensuite créer les relations entre nos noeuds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start2 = tm.time() # Pour mesurer le mis pour créer la base de donnée avec Neo4J. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des noeuds (neo4j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La création des tables correspond aux noeuds. Nous montrerons ici comment créer une table dans Neo4j à partir d'un document csv (écuries). La méthode est ensuite la même pour toutes les tables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Données écuries :  Constructors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le principe consiste à créer une table vide puis, en bouclant, introduire chaque ligne de notre document csv comme part du noeud principal 'constructor'.    \n",
    "Py2neo créera ainsi les tables dans Neo4j à partir du fichier csv transformé en pandas dataframe. Pour eviter toutes erreurs d'importation dues aux caratères spéciaux, on rajoute errors = \"ignore\", encoding='uft-8'.Le principe de la boucle est relativement simple: la fonction l.split permet de diviser le fichier csv en différentes colonnes en lui précisement le caractère de spération utilisé dans le fichier csv.\n",
    "L'étape suivante consiste à créer un noeud avec des caractéristiques (id, nom, ect...).\n",
    "Ces caractéristiques sont celles de la table csv et sont attribués au noeud en indiquant le numero de la colonne attribué par la fonction l.split. Par exemple, le noeud 1, corresspondant à la première ligne de la table excel, aura le lieux de la 1ere ligne du tableau excel pour l'attribut location. Il n'est pas nécéssaire de conserver toutes les colonnes du fichier csv. Seules celles qui nous intéressent sont gardées en reférencant leur numéro de colonne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constructors = {}\n",
    "\n",
    "with open(path_to_data+\"constructors.csv\", \"r\") as f:\n",
    "    first = True\n",
    "    for l in f :\n",
    "        if not first:\n",
    "            col = l.split(\",\")\n",
    "            constructors[col[0]] =  Node(\"Constructor\",\n",
    "                                  id = int(col[0]),\n",
    "                                  name = str(col[2]),\n",
    "                                  nationalityC=str(col[3])) #rajouter.strip a la fin si marche pas ?\n",
    "        else :\n",
    "            first = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces étapes sont répétées pour les autres fichiers csv.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = tm.time()\n",
    "# ____# Table circuits #_______\n",
    "circuits = {}\n",
    "\n",
    "with open(path_to_data+\"circuits.csv\", \"r\", errors='ignore', encoding='utf-8') as f:\n",
    "    first = True\n",
    "    for l in f :\n",
    "        if not first:\n",
    "            col = l.split(\",\")\n",
    "            circuits[col[0]] =  Node(\"Circuit\",\n",
    "                                  circuitId = int(col[0]),\n",
    "                                  name = str(col[2]),\n",
    "                                  location=str(col[3]),\n",
    "                                  country=str(col[4]))\n",
    "        else :\n",
    "            first = False\n",
    "               \n",
    "races = {}\n",
    "\n",
    "with open(path_to_data+\"races.csv\", \"r\") as f:\n",
    "    first = True\n",
    "    for l in f :\n",
    "        if not first:\n",
    "            col = l.split(\",\")\n",
    "            races[col[0]] =  Node(\"Race\",\n",
    "                                  id = int(col[0]),\n",
    "                                  year= int(col[1]),\n",
    "                                  tour=str(col[2]),\n",
    "                                  circuitId=int(col[3]),\n",
    "                                  name=str(col[4]),\n",
    "                                  date=str(col[5])) #rajouter.strip a la fin si marche pas ?\n",
    "        else :\n",
    "            first = False\n",
    "\n",
    "#pd.DataFrame(races)\n",
    "\n",
    "# ____# Table pilote #_______\n",
    "drivers = {}\n",
    "\n",
    "with open(path_to_data+\"drivers.csv\", \"r\", errors='ignore', encoding='utf-8') as f:\n",
    "    first = True\n",
    "    for l in f :\n",
    "        if not first:\n",
    "            col = l.split(\",\")\n",
    "            drivers[col[0]] =  Node(\"drivers\",\n",
    "                                  id = int(col[0]),\n",
    "                                  code= str(col[3]),\n",
    "                                  name=str(col[4]),\n",
    "                                  surname=str(col[5]),\n",
    "                                  birth=str(col[6]),\n",
    "                                  nationality=str(col[7]))\n",
    "        else :\n",
    "            first = False\n",
    "\n",
    "# pd.DataFrame(drivers)\n",
    "\n",
    "#____# Table Résultats #_______\n",
    "results = {}\n",
    "df = pd.read_csv(path_to_data+\"results.csv\",delimiter=\",\")\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    #print(row)\n",
    "    results[row['resultId']] = Node(\"Result\",\n",
    "                                id=int(row['resultId']),\n",
    "                                race=int(row[\"raceId\"]),\n",
    "                                driver=int(row[\"driverId\"]),\n",
    "                                constructor=int(row[\"constructorId\"]),\n",
    "                                position=str(row[\"position\"]),\n",
    "                                positionOrder=str(row[\"positionOrder\"]),\n",
    "                                points=int(row[\"points\"]),\n",
    "                                time=str(row[\"time\"]),\n",
    "                                rank=str(row[\"rank\"]))\n",
    "#pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette seconde étape nous créeons les relations entre les noeuds précédemment faits. La première étape consiste ici à créer un repertoire de relation vide que l'on viendra enrichir par la création de nos relations. Sur le même principe que la première partie, la méthode de création de la première relation servira de modèle pour les suivantes. \n",
    "La relation créée ici est la relation entre la course (Race) et le circuit (Circuit) sur lequel elle a eu lieu nommé \"took_place_on\". Afin de rester cohérent dans notre analyse nous lui avons donné le même nom que pour la relation corrrespondante pour Orientdb. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel=[] # Créatio  d'une liste vide que nous viendrons populer\n",
    "\n",
    "# Relation Race-Circuit : \"SUR LE CIRCUIT\" ###\n",
    "# La première étape consiste à importer le document csv ou les deux informations sont reliées (présentes sur sur la même ligne).\n",
    "df = pd.read_csv(path_to_data+\"races.csv\",delimiter=\",\")\n",
    "\n",
    "# Puis le principe consiste à indiquer dans quelle colone (du document csv) on va retrouver l'information.\n",
    "# (On peut le faire par le numéro de la colonne avec l.split ou avec le nom de la colonne)\n",
    "for index,row in df.iterrows():\n",
    "    course = races[str(row['raceId'])]\n",
    "    # Pour l'information concernant la course c'est dans la colonne 'raceId' \n",
    "    # Pour la première ligne, raceId = 1 \n",
    "    circuit = circuits[str(row['circuitId'])]\n",
    "    # Pour l'information concernant le circuit c'est dans la colonne 'circuitId'\n",
    "    # Pour la première ligne du doc csv, circuitId = 1 \n",
    "    rel.append(Relationship(course,\"Took_place_on\",circuit))\n",
    "    # Ici on lie alors par la relation \"SUR LE CIRCUIT\" \n",
    "    # le noeud de la base circuit, dont le circuitId = 1,  \n",
    "    # avec le noeud de la base races, dont le raceId = 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les relations suivantes suivent la même méthode/structure\n",
    "\n",
    "# Relation Résulats - course : results_of\n",
    "df = pd.read_csv(path_to_data+\"results.csv\",delimiter=\",\")\n",
    "for index,row in df.iterrows():\n",
    "    resultat = results[row['resultId']]\n",
    "    course = races[str(row['raceId'])]\n",
    "    rel.append(Relationship(resultat,\"results_of\",course))\n",
    "    \n",
    "# Relation Résulats - Pilote : d_results\n",
    "df = pd.read_csv(path_to_data+\"results.csv\",delimiter=\",\")\n",
    "for index,row in df.iterrows():\n",
    "    resultat = results[row['resultId']]\n",
    "    pilote = drivers[str(row['driverId'])]\n",
    "    rel.append(Relationship(pilote,\"d_results\",resultat))\n",
    "\n",
    "# Relation Résulats - Ecurie : c_results\n",
    "df = pd.read_csv(path_to_data+\"results.csv\",delimiter=\",\")\n",
    "for index,row in df.iterrows():\n",
    "    resultat = results[row['resultId']]\n",
    "    constructeur = constructors[str(row['constructorId'])]\n",
    "    rel.append(Relationship(constructeur,\"c_results\",resultat))\n",
    "\n",
    "# relation Pilote - Course : \"participated_to\"  \n",
    "df = pd.read_csv(path_to_data+\"results.csv\",delimiter=\",\")\n",
    "for index,row in df.iterrows():\n",
    "    course = races[str(row['raceId'])]\n",
    "    pilote = drivers[str(row['driverId'])]\n",
    "    rel.append(Relationship(pilote,\"participated_to\",course))\n",
    "\n",
    "    \n",
    "for r in rel :\n",
    "    graph_db.create(r)\n",
    "\n",
    "end2 = tm.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"La création de la base de donnée avec py2neo a nécessité\" + \" \" + str(round(end2 - start2, 2)) + \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous checkons ici si la base de donnée a été bien créée dans Neo4J\n",
    "from py2neo import Graph\n",
    "graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"merlin\"))\n",
    "try:\n",
    "    graph.run(\"Match () Return 1 Limit 1\")\n",
    "    print('ok')\n",
    "except Exception:\n",
    "    print('not ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_use_neo4j = psutil.virtual_memory()[2] # Comme pour orientdb nous calculons le coût en mémoire de la création de cette de donnée. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos bases de données ont été ainsi créées sur Orientdb et Neo4J à partir de nos commandes Python. Nous allons pour la suite essayer de souligner les différences au travers de requêtes graduellement complexes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### c. Requêtes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons dans cette partie réaliser 5 requêtes. La première permettant juste de constater avec vous les résultats brûts des requêtes pour chaque SGBD. En tant que data scientists en devenir nous pensons aussi qu'il est intéressant pour cet exposé de ne pas nous limiter quaux requêtes mais aussi d'être de la connaissance à partir de ces données. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  > #### Récupération d'une quantité limitée de données "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour orientdb toujours à l'aide de la méthode command() du client pyorient nous recevons de la part du serveur des pointeurs (pyorient.otypes.OrientRecord) ainsi que leur localisatiion en mémoire (0x11ba5b890). Comme mentionné au début de notre présentation Orientdb met au centre de sa logique architecturale la notion de link qui pointent vers des cursors (des pointeurs). Chaque requête nous revient donc comme un pointeur où le résultat est stocké. Il est nécessaire par la suite \"d'ouvrir\" ce pointeur et de récupérer les dictionnaires contenant les \"données utiles\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.command(\"SELECT * FROM took_place_on LIMIT 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour Neo4J la tâche est beaucoup moins ardue même si ce sont tout de même des pointeurs qui sont renvoyés, il est possible d'entrevoir la forme que prennent les données. Il suffira par la suite d'itérer dans des listes de listes au niveau de dictionnaires pour récupérer les champs qui nous intéressent. Notons ici que Neo4J accepte Cypher comme language de requête. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Get some data # ok\n",
    "graph_db.run(\"MATCH (n1)-[r]->(n2) RETURN r, n1, n2 LIMIT 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  > #### a- Liste des pilotes allemands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici nous requêtons tous les allemands de notre table Drivers. Comme vous pouvez le constater dans le chunk ci-dessous il est nécessaire, après avoir récupéré les pointeurs, de l'ouvrir et d'itérer sur la liste contenant les données (_OrientRecord__o_storage _). De là de simples opérations de manipulation de dictionnaires (assez pythoniques) sont nécessaires pour obtenir un dataframe pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start3 = tm.time()\n",
    "\n",
    "german_pilots = client.command(\"SELECT forename, surname, nationality FROM Drivers WHERE nationality='German'\") \n",
    "pilots_list = [] \n",
    "values_dict = []\n",
    "keys_dict = []\n",
    "\n",
    "for i in range(len(german_pilots)):\n",
    "    pilots_list.append(german_pilots[i].__dict__)\n",
    "    values_dict.append(list(pilots_list[i][\"_OrientRecord__o_storage\"].values()))\n",
    "    df = pd.DataFrame(values_dict)\n",
    "    \n",
    "keys_dict = list(pilots_list[1][\"_OrientRecord__o_storage\"].keys())\n",
    "df.columns = keys_dict\n",
    "end3 = tm.time()\n",
    "df.sort_values('surname')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De maniére équivalente, nous pouvons retrouver le même dataframe en requêtant la base de donnée située sur Neo4J. Notons ici que pour Cypher une commande Match suffit à extraire la donnée. Sur orientdb une selection (avec Select) est nécessaire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start4 = tm.time()\n",
    "query_res = graph_db.run(\"MATCH (d:drivers) WHERE d.nationality= '\\\"German\\\"' RETURN d.name, d.surname, d.nationality\").data()\n",
    "df = pd.DataFrame(query_res)\n",
    "df.columns = ('name', \"surname\", \"nationality\")\n",
    "df.head()\n",
    "df[\"name\"] = df[\"name\"].str.replace(r\"[\\\"]\",\" \") \n",
    "df[\"surname\"] = df[\"surname\"].str.replace(r\"[\\\"]\",\" \") \n",
    "df[\"nationality\"] = df[\"nationality\"].str.replace(r\"[\\\"]\",\" \") \n",
    "end4 = tm.time()\n",
    "df.sort_values('surname')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette requête spécifique, nous pouvons aussi récuper le temps mis par chacun des deux SGBD pour nous renvoyer les mêmes données. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orient_time = end3 - start3\n",
    "orient_time\n",
    "neo4j_time = end4 - start4\n",
    "orient_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment on these times**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  > #### b- Pilote les plus titrés de l'histoire top 7 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'après Wikipédia 213 pilotes de F1 sont déjà monté sur le podium des championnats du monde. Nous cherchons à travers la requête suivante quels  pilotes ont été les plus titrés. Pour cela nous basons notre classement sur le champ rank de la table Results. N'ayant aucune autre précision de la part du fournisseur du dataset, nous supposons qu'il s'agit du rang par course (à distinguer de position qui pour nous correspond aux positions de départ appelé dans le jargon de la F1 la \"Pole Position\"). Nous utilisons ici pour pyorient l'alternative de command() que constitue query() et limitons nos résultats au top 7. La commande SQL correspondante est assez intuitive. Nous utilisons les relations qui existent entre noeuds pour obtenir cette donnée.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top7 = client.query(\"SELECT d.surname d.forename as forename,  as surname,, d.nationality as nationality, count(r) as nb_Title\" \n",
    "                    \"FROM (MATCH {class: Drivers, as: d}-d_results-{class: Results, as: r,WHERE :(rank=1)} Return d, r)\" \n",
    "                    \"GROUP BY d.forename ORDER BY nb_Title desc LIMIT 7\")\n",
    "values_dict = []\n",
    "keys_dict = []\n",
    "pilots_list = []\n",
    "\n",
    "for i in range(len(top7)):\n",
    "    pilots_list.append(top7[i].__dict__)\n",
    "    values_dict.append(list(pilots_list[i][\"_OrientRecord__o_storage\"].values()))\n",
    "    df = pd.DataFrame(values_dict)\n",
    "    \n",
    "keys_dict = list(pilots_list[2][\"_OrientRecord__o_storage\"].keys())\n",
    "df.columns = keys_dict\n",
    "end2 = tm.time()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La commande équivalente avec py2neo est tout aussi intuitive. Elle est aussi surtout \"bavarde\" et se limite à de simples liaisons. Aussi pour une raison qui nous échappe encore. En n'utilisant que la commande graph.run() pour py2neo une sorte de dataframe tabulée nous est retournée et elle limite la sortie à trois individus même si cette sortie reste très intéressante car déjà formatée visuellement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_db.run(\"Match (p:drivers)-[:`d_results`]-(res:Result {rank:'1'}) Return p.name as name,p.surname as surname\" \n",
    "             \",p.nationality as nationality, count(res) as nb_Title ORDER BY nb_Title desc LIMIT 7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En mettant ce résultat dans une liste nous arrivons à receuillir comme avec pyorient les 7 meilleur au championnat du monde. Nous choissisons de ne pas formatter cette sortie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(graph_db.run(\"Match (p:drivers)-[:`d_results`]-(res:Result {rank:'1'}) Return p.name as name,p.surname as surname\" \n",
    "             \",p.nationality as nationality, count(res) as nb_Title ORDER BY nb_Title desc LIMIT 7\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous représentons ici graphqiue avec seaborn cette sortie et constatons la présence des pilotes européens et surtout allemands dans les hautes sphères. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"surname\", y=\"nb_Title\", hue=\"nationality\", data=df)\n",
    "from IPython.core.display import HTML as Center\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    ".output {\n",
    "    display: flex;\n",
    "    align-items: center;\n",
    "    text-align: center;\n",
    "}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  > #### c- Classement historique des écuries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les pilotes ne roulent cependant pas tous seuls. Ils sont employés par des écuries qui mettent leur ingéniosité à la construction de leurs bolides. Il nous a paru donc logique de nous intéresser à l'évolution des classements des écuries sachant par contre qu'il existe un gap assez important entre les écuries historiques comme l'italien Ferrari, le britannique McLaren et l'allemand Mercedes qui font rouler des pilotes de qualité depuis plus d'un demi-siécle. \n",
    "Afin d'extraire cette information nous utilisons de nouveau des commandes simples empruntés de SQL avec un schéma de la sorte : Select -> Count -> Match -> relationship -> Group By -> Order By. De simples commandes python suffisent par la suite à créer le dataframe avec le nombre de victoires par année pour chaque écurie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_res = client.command(\"SELECT co.cons_name as name, ra.year as year, count(r) as nb_victories FROM\" \n",
    "\t\"(MATCH {class: Races, as: ra}<-results_of-{class: Results, as: r, WHERE : (rank=1)}<-c_results-{class: Constructors, as: co}\"\n",
    "      \"Return co,ra, r) GROUP BY co.cons_name, ra.year ORDER BY ra.year desc\")\n",
    "values_dict = []\n",
    "keys_dict = []\n",
    "pilots_list = []\n",
    "\n",
    "for i in range(len(cons_res)):\n",
    "    pilots_list.append(cons_res[i].__dict__)\n",
    "    values_dict.append(list(pilots_list[i][\"_OrientRecord__o_storage\"].values()))\n",
    "    df = pd.DataFrame(values_dict)\n",
    "    \n",
    "keys_dict = list(pilots_list[2][\"_OrientRecord__o_storage\"].keys())\n",
    "df.columns = keys_dict\n",
    "end2 = tm.time()\n",
    "df.sort_values('nb_victories')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La même logique est utilisée dans Neo4J sans la commande Select. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_db.run(\"Match (c:Constructor)-[:`c_results`]-(res:Result {rank:'1'}),\" \n",
    "                \"(res:Result {rank:'1'})-[:`results_if`]-(r:Race)\" \n",
    "                \"Return c.name as name , r.year as year ,count(res) as nb_victories ORDER BY nb_victories desc\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de valoriser ces données nous optons pour une visualisation de séries temporelles qui prend de plus en plus de l'importance en data sciences : les race bar chart. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XXXXXX faire ce foutu graph ici XXXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment race bar chart "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  > #### d- Shortest paths - visualisation réseau "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que serait ce travail sur des SGBD orientés graphes sans la recherche chemins le plus rapide ? Cette fonctionalité a permis le passage à l'échelle de ces technologies dans des domaines comme la biologie où les bioinformaticiens cherchent les voies de régulations de certains procédés métaboliques complexes (comme la néoglucogenèse). Dans notre exemple nous cherchons nous le chemin le plus cours entre l'écurie Mercedes et le circuit turc Istanbul Park. \n",
    "Malheursement les développeurs des drivers pyorient et py2neo n'ont pas ajouté de fonctionalités permettant de représenter directement sur Python les graphes disponible dans les desktops d'Orientdb et de Neo4J. Aussi, même la requête de type graphe ne semble pas être pris en charge d'après nos recherches. Si cela avait été le cas, nous aurions utilisé la librarie [networkx](https://networkx.org/documentation/stable/tutorial.html) pour représenter des réseau interactives. \n",
    "À défaut de vous proposer des graphes interactives de nos chemins les plus courts, nous vous proposer des captures d'écran de nos desktop correspondant aux résultats de nos requêtes.<br>\n",
    "\n",
    "Sur orientdb la fonction shortestPath retourne facilement le chemin le plus court entre deux noeuds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # commande pour ne pas exécuter cette ligne de code \n",
    "client.command(\"SELECT expand(path) FROM (SELECT shortestPath((SELECT FROM Constructors WHERE cons_name='Mercedes'), \n",
    "                                             \"(SELECT FROM Circuits WHERE name='Istanbul Park')) AS path \n",
    "                                              \"UNWIND path\"\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous vous proposons de plus ici une alternative à la fonction Select pour désigner les noeuds de départ et d'arrivée. Il s'agit d'utiliser littéralement les \"built-in id\" d'OrientDB appelés les @rid pour \"record id\". Ainsi chaque donnée ayant un id spécifique créée par le SGBD lui même vous pourrez, si votre but de réduire le vocabulaire de vos requêtes, les passer à vos fonctions. Vous aurez le même résultat. La figure 6 montre le chemin le plus court entre Mercedes et Istanbul Park avec 2 noeuds intermédiaires.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "client.command(\"SELECT expand(path) FROM(SELECT shortestPath(#23:20, #26:17) AS path UNWIND path\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/129HH38/sp-odb.png\" width=\"1100\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Figure 6 : Capture d'écran du chemin le plus court Mercedes-Istanbul Park avec OrientDB Studio  </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La même commande sur Neo4J nécessite beaucoup moins de code et semble un peu plus comprehensible pour un non initié. Le résultat présenté figure 7 est le même que celui obtenu avec orientdb. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_db.run(\"EXPLAIN MATCH (e:Constructor {name:'Mercedes'}), (c:Circuit {name:'Istanbul Park'}), p=shortestpath((e)-[*]-(c)) Return p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/0rSdQn9/sp-neo4J.png\" width=\"1100\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Figure 7 : Capture d'écran du chemin le plus court Mercedes-Istanbul Park avec Neo4J Studio  </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. **Conclusion sur la comparaison et Limites de notre approche**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a- Comparaison sur des points précis  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous l'avons vu dans la seconde partie de ce rapport, ces deux systèmes de gestion de base de données sont semblables à bien des égards. Ceci dans la logique de création de bases de données en définissant d'abord les noeuds puis les relations qui les lient mais aussi dans la construction des requêtes. Ce qui semble normal vu qu'ils utilisent tous deux la théorie du stockage de données dans des objets de types graphes avec une programmation totalement orientée objets. Dès lors, afin d'enrichir cette comparaison, nous avons identifié 5 points qui pour nous sont pertinents pour des SGBDs devant gérer des données massives. Il s'agit : \n",
    "- du temps de calcul (pour créer entièrement la base de donnée et retourner les résultats des requêtes);\n",
    "- de l'utilisation de mémoire ordinateur;\n",
    "- de l'intuitivité;\n",
    "- de la disponibilité des aides et de la communauté;\n",
    "- des outils spécifiques permettant à un SGBD de gérer des données massives; \n",
    "\n",
    "Dans cette partie de notre rapport nous veillons aussi de mettre en commun les expériences que chacun des étudiants ayant travaillé sur l'un ou l'autre SGBDs. Il s'agit donc au delà des chiffres plus d'une synthèse de ce que nous avons expérimenté. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Temps de calcul "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Comme l'ont montré les chiffres de temps de création de base de données, Neo4j plus puissant pour prendre en considération tous les noeuds et les lier entre eux avec des relations. Pyorient a en effet souffert pour créer les relations impliquant la table Results (très lourde) ceci même en utilisant du Batch. Cependant comme nous l'avons vu dans la fin de la partie 2.b pyorient n'a pas réellement pour vocation de créer une base de donnée à partir de données partagées dans des tables csv. L'équipe de développement préconise surtout de l'ETL qui pour nous se fait en quelques seconds à partir de l'invite de commande. Nous ne recommandons donc pas d'utiliser pyorient pour créer votre bae de donnée mais plutôt de l'ETL. Neo4j propose aussi dans son desktop de faire de l'ETL mais aussi d'utiliser des \"bulk insert\" qui sont des équivalents du Batch sur OrientDB. \n",
    "Quoiqu'il en soit pour nous py2neo a sur ce point de la vitesse et du temps de calcul plus intéressant. Concernant les délais de retour des requêtes, nous préferons ne pas nous avancer sur des conclusions au vu de la simplificité des tâches que nous demandions aux deux SGBD. Il faudrait en effet pour cela des requêtes qui demandent plus de travail aux SGBD et qui ne prennent pas en moyenne 0.2secondes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparaison sur l'utilisation de la mémoire ordinateur "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concernant l'utilisation de la mémoire ordinateur, il semblerait que les deux SGBD soient tout aussi semblables. Cependant, nous souhaitons aussi relativiser ce résultat sachant que la gestion de la mémoire par neo4j calculée a pu être altérée par celle d'orientdb. Cependant, nos [recherches](https://www.arangodb.com/2018/02/nosql-performance-benchmark-2018-mongodb-postgresql-orientdb-neo4j-arangodb/#Memory) ont montré qu'OrientDB est beaucoup plus performant que Neo4j sur ce point.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_use_orientdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_use_neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Intuitivité // Facilité de la prise en main "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce point est extrêmement important pour nous qui sommes pour la plupart issus de cursus autres que l'informatique pur. De fait, un SGBD doit pouvoir nous permettre de manière assez simple et efficace de créer, lire et requêter une base de donnée sans pour autant avoir à appréhender certaines concepts mathématiques complexes de l'informatique. Pour nous ces deux SGBD ont réussi ce pari. Que cela soit pour l'utilisation d'objets géométriques de types graphes ou la prise en main des versions Desktop (studios) qui sont tous les deux user-friendly. Néanmoins, notre expérience de Neo4j avec py2neo a été plus agréable. Malgré qu'Orientdb soit très puissant il est nécessaire pour certains tâches de s'y prendre à plusieurs reprises pour en comprendre réellement le sens et ne plus faire certaines erreurs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Communauté // Aide en ligne // Accessibilité de la documentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pensons aussi qu'en tant qu'apprentis data scientists il est très important de pouvoir avoir de l'aide quand on rencontre certaines erreurs. Lors de ces situations notre premier réflexe est sans nul doute de copier l'erreur directement dans Google et de nous retrouver sur Stackoverflow ou sur la partie \"issues\" du github de la technologie avec laquelle nous travaillons. Et sur ce point Neo4j remporte la compétition haut la main. La communauté Neo4j est extrêmement active et coopérative. Elle est sûrement à l'origine du succès de cette technologie. La figure suivante présente de le nombre de questions des tags [orientdb](https://stackoverflow.com/questions/tagged/orientdb) et [neo4j](https://stackoverflow.com/questions/tagged/neo4j) sur stackoverflow ainsi que le nombre de répertoires github impliquant les SGBD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "sof_orientdb = 2667\n",
    "sof_neo4j = 20053\n",
    "rep_orientdb = 947\n",
    "rep_neo4j = 11464\n",
    "# sof pour stackoverflow et rep comme répertoire sur github\n",
    "x = [\"sof_orientdb\", \"sof_neo4j\", \"rep_orientdb\", \"rep_neo4j\"]\n",
    "y = [2667, 20053, 947, 11464]\n",
    "\n",
    "bars = plt.bar(x, y)\n",
    "bars[0].set_color('orange')\n",
    "bars[2].set_color('orange')\n",
    "plt.xlabel('technologie')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Popularité Orientdb VS Neo4J')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La popularité de Neo4j est sans conteste. D'autant plus, les deux technologies ont toutes deux été lancées début 2010. Nos interrogations par rapport à OrientDB ont eu plus de mal à trouver de réponses et nous avons rencontré quelques difficultés pour la prise en main. Cependant, passé cette première étape et à l'aide de nos bases en SQL nous arrivons très facilement à nous débrouiller avec la technologie. La documentation d'OrientDB est aussi très complète et montre grâce à des exemples simples l'implémentation de toutes les fonctionnalités proposées.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gestion données massives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données massives étant l'objet de ce cours, nous souhaitons consacrer cette dernière partie aux fonctionnalités proposées par chacun des deux SGBD pour les manipuler. \n",
    "Grâce à leur structure en graph les deux techologies gérent assez bien d'importantes quantités de données et leur visualisation rapide. OrientDB donne la possibilité d'utiliser une fonctionalité en architecture distribuée appelée Sharding (partitionnement direct en français). Il s'agit d'une méthode de morcelement d'une classe de données sur plusieurs noeuds appelés **shards**. Et contrairement à une simple réplication, la classe possède son cluster par défaut sur un des noeuds qui est le seul point d'entrée pour traiter les données de ladite classe. Les manipulations se font dans le périmètre de ce cluster puis les réplicats sont mis à jour. Chaque cluster dans ce ca être attribué à un ou plusieurs serveurs. Ceci permet d'utiliser toute la puissance de l'architecture distribué du SGBD. OrientDB supporte aussi le MapReduce sans usage de Hadoop qui plus est. Ici des requêtes SQL simples et verbalement parlant sont utilisés. Cette technique est utilisée lorsque plusieurs clusters ou shards sont impliqués dans une requête. Orientdb exécute la requête dans tous les clusters (shards) impliqués, il s'agit de l'étape MAP puis regroupe tous les résultats, c'est le REDUCE. Notre jeu de données ne se prétant pas à cette opération nous vous renvoyons vers la documentation d'OrientDB pour un exemple d'application [ici](https://orientdb.com/docs/2.2.x/Distributed-Sharding.html#mapreduce). Neo4j ne propose pas de méthodes de MapReduce. Même si il est possible de contourner cette limitation en  utilisant Hadoop comme orchestrateur. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En résumé "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tableau comparatif final ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b- Limites de notre approche "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre comparaison semble avoir montré quelques points de dvergence assez importants entre ces deux SGBD-G. Toutefois, nous pensons que notre approche comporte certaines limites dont nous sommes bien conscient. Nous les listons ici : <br>\n",
    "- nous avons débuté cette comparaison en ayant d'abord était initié à Neo4j lors d'une séance de travaux dirigés, nos connaissances à priori plus importantes de ce SGBD par rapport à OrientDB a sûrement biaisé certaines de nos conclusions;  \n",
    "- le dataset employé pour cette comparaison ne correspond pas vraiment aux caractéristiques du Big data. Il aurait fallu des données plus importantes pour pouvoir exploiter au mieux les capacités de nos deux SGBD; Mais comme nous l'avons vu en cours, il n'est pas possible de trouver des fichier répondant à la définition et de les gérer depuis un  ordinateur équipé de capacité limités en termes de processeur (CPU);\n",
    "- l'importation des données sur OrientDB se fait principalement avec de l'ETL, donc ce SGBD est peut-être parti avec un léger handicap; \n",
    "- Les différences de niveaux en Python des différents testeurs ont pu défavoriser d'une façon ou d'une autre l'un des SGBD;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En définitive, nous pensons que Neo4j reste le SGBD de référence pour les bases de données orientées graphes. Cependant, l'absence de technologie claire permettant de faire du MapReduce lui fait perdre quelques points par rapport aux autres SGBD similaires. OrientDB est une fantastique technologie capable de gérer très simplement des données massives. Sa version desktop OrientDB Studio est très agréable et facile d'utilisation, et offre la possibilité de visualiser plus facilement les graphes. Les deux technologies se valent et offrent toutes deux des fonctionnalités intéressantes.  <br>\n",
    "Ce travail nous a permis de découvrir un peu plus les SGBDs graphes et leur fonctionnement. Mais aussi de parfaire nos capacités de prise en main d'une question en Data Sciences et plus généralement de programmation avec Python, Cypher et SQL. \n",
    "Pour aller plus loin dans la comparaison entre les deux SGBDs, nous conseillons [ce document](https://www.irit.fr/~Thierry.Millan/MemoiresENG221/Nicolas_vergnes.pdf) du Conservatoire National des Arts et Métiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Références:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.irit.fr/~Thierry.Millan/MemoiresENG221/Nicolas_vergnes.pdf <br>\n",
    "https://orientdb.com/docs/2.2.x/PyOrient.html <br>\n",
    "https://neo4j.com/developer/get-started/ <br>\n",
    "https://www.udemy.com/join/login-popup/?next=/course/orientdb-getting-started/learn/lecture/1726168#overview <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
